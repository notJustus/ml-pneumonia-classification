{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ac93d3-e6e2-4817-b9e1-1ce3e037cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15e901c-ffd2-474b-999b-423ec0c2bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/anonymous/Desktop/ml/data/chest_xray/chest_xray/train'\n",
    "val_dir = '/Users/anonymous/Desktop/ml/data/chest_xray/chest_xray/val'\n",
    "test_dir = '/Users/anonymous/Desktop/ml/data/chest_xray/chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6e47e0-a9c1-47d2-bade-fc7746288267",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    images = [] \n",
    "    labels_list = []\n",
    "    \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                flattened_arr = resized_arr.flatten()  # Flatten the image array\n",
    "                images.append(flattened_arr)\n",
    "                labels_list.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "    images_array = np.array(images)\n",
    "    labels_array = np.array(labels_list)\n",
    "    \n",
    "    data = np.column_stack((images_array, labels_array))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313ad165-6e53-4f98-8d47-f55ea7475c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = get_training_data(train_dir)\n",
    "val = get_training_data(val_dir)\n",
    "test = get_training_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbaed06c-ae45-4373-aeda-80a6b25b1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_minority(data):\n",
    "    # Count the number of normal and disease images\n",
    "    normal_indices = np.where(data[:, -1] == 1)[0]  # Indices of normal images\n",
    "    disease_indices = np.where(data[:, -1] == 0)[0]  # Indices of disease images\n",
    "\n",
    "    normal_count = len(normal_indices)\n",
    "    disease_count = len(disease_indices)\n",
    "\n",
    "    # Calculate the number of samples needed to balance the classes\n",
    "    oversample_count = disease_count - normal_count\n",
    "\n",
    "    if oversample_count <= 0:\n",
    "        print(\"No oversampling needed.\")\n",
    "        return data\n",
    "\n",
    "    # Randomly sample some normal images to add to the dataset\n",
    "    oversampled_indices = np.random.choice(normal_indices, size=oversample_count, replace=True)\n",
    "\n",
    "    # Concatenate the oversampled indices with the original dataset\n",
    "    oversampled_data = data[oversampled_indices]\n",
    "    balanced_data = np.vstack((data, oversampled_data))\n",
    "\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f493226-8e95-4450-b013-68e072bfd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = oversample_minority(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6707450c-3e38-44fb-acba-6eb99c397a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    x_train = []  # Feature array (pixel data)\n",
    "    y_train = []  # Label array\n",
    "\n",
    "    for entry in data:\n",
    "        # Append image data to x_train\n",
    "        x_train.append(entry[:-1])  # Exclude the last element (label) from the entry\n",
    "        \n",
    "        # Append label to y_train\n",
    "        y_train.append(entry[-1])  # Last element in the entry is the label\n",
    "\n",
    "    # Convert lists to NumPy arrays for efficiency\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edcbb951-7bc3-4aed-b328-0eb8b5086cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_data(train)\n",
    "x_val, y_val = split_data(val)\n",
    "x_test, y_test = split_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa7d9ff-aee1-4859-a4cd-714e816956e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ecb20c-8d19-46bf-ba66-bb58987eadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140213f5-b6fd-40d7-9461-c2717dee0e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f698b4ba-3202-4022-9b96-b4bab3b0f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 150, 150, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 150, 150, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 75, 75, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 75, 75, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 38, 38, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 38, 38, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 38, 38, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 19, 19, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 19, 19, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 19, 19, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 10, 10, 256)       295168    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 10, 10, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 10, 10, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1246401 (4.75 MB)\n",
      "Trainable params: 1245313 (4.75 MB)\n",
      "Non-trainable params: 1088 (4.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "109d2069-73b3-4e3c-901a-4b6ba9da6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d8fd7b3-ddd8-4960-a577-e9e0ea5bc87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99711518-eedd-4c84-b88a-f03612cf4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "243/243 [==============================] - 153s 624ms/step - loss: 0.4558 - accuracy: 0.8539 - val_loss: 14.4205 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/12\n",
      "243/243 [==============================] - 214s 879ms/step - loss: 0.2545 - accuracy: 0.9093 - val_loss: 3.0093 - val_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 3/12\n",
      "243/243 [==============================] - 157s 647ms/step - loss: 0.1919 - accuracy: 0.9317 - val_loss: 1.5276 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/12\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9375\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "243/243 [==============================] - 193s 793ms/step - loss: 0.1830 - accuracy: 0.9375 - val_loss: 2.2844 - val_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 5/12\n",
      "243/243 [==============================] - 161s 664ms/step - loss: 0.1285 - accuracy: 0.9550 - val_loss: 1.1048 - val_accuracy: 0.7500 - lr: 3.0000e-04\n",
      "Epoch 6/12\n",
      "225/243 [==========================>...] - ETA: 11s - loss: 0.1129 - accuracy: 0.9613"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 12 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a4c25-ab16-45cc-b001-2582d0b7b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
